{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def pearson_correlation_scatterplot(df, cols,\n",
        "                                    title= \"Pearson Correlation Scatterplot\",\n",
        "                                    xlabel= None, ylabel = None):\n",
        "    \"\"\"\n",
        "    Creates a scatterplot for two specified columns from the DataFrame,\n",
        "    calculates the Pearson correlation coefficient, and displays the plot.\n",
        "\n",
        "    Parameters:\n",
        "      df : pd.DataFrame\n",
        "          The input DataFrame containing the data.\n",
        "      cols : list\n",
        "          List of two column names (as strings) for which the scatterplot and correlation\n",
        "          coefficient will be computed.\n",
        "      title : str, optional\n",
        "          The title for the scatterplot. Default is \"Pearson Correlation Scatterplot\".\n",
        "      xlabel : str, optional\n",
        "          Label for the x-axis. If None, the first column name from cols is used.\n",
        "      ylabel : str, optional\n",
        "          Label for the y-axis. If None, the second column name from cols is used.\n",
        "\n",
        "    Returns:\n",
        "      corr_coef : float\n",
        "          The computed Pearson correlation coefficient.\n",
        "      p_value : float\n",
        "          The p-value for testing non-correlation.\n",
        "    \"\"\"\n",
        "    if len(cols) != 2:\n",
        "        raise ValueError(\"Exactly two columns must be provided for Pearson correlation.\")\n",
        "\n",
        "    x_col, y_col = cols\n",
        "    x = df[x_col]\n",
        "    y = df[y_col]\n",
        "\n",
        "    # Calculate the Pearson correlation coefficient and p-value.\n",
        "    corr_coef, p_value = pearsonr(x, y)\n",
        "\n",
        "    # Setup axis labels if not provided.\n",
        "    if xlabel is None:\n",
        "        xlabel = x_col\n",
        "    if ylabel is None:\n",
        "        ylabel = y_col\n",
        "\n",
        "    # Create scatter plot.\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(x, y, alpha=0.7, c='blue', edgecolors='w', s=100)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "\n",
        "    # Display the correlation coefficient on the plot.\n",
        "    plt.text(0.05, 0.95, f\"Pearson r = {corr_coef:.3f}\\np-value = {p_value:.3g}\",\n",
        "             transform=plt.gca().transAxes,\n",
        "             verticalalignment='top', bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5))\n",
        "\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return corr_coef, p_value"
      ],
      "metadata": {
        "id": "1Ve1YUVvSEyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spearman_correlation_scatterplot(df, cols,\n",
        "                                    title= \"spearman rank Correlation Scatterplot\",\n",
        "                                    xlabel= None, ylabel = None):\n",
        "    \"\"\"\n",
        "    Creates a scatterplot for two specified columns from the DataFrame,\n",
        "    calculates the Spearman's rank correlation coefficient, and displays the plot.\n",
        "\n",
        "    Parameters:\n",
        "      df : pd.DataFrame\n",
        "          The input DataFrame containing the data.\n",
        "      cols : list\n",
        "          List of two column names (as strings) for which the scatterplot and correlation\n",
        "          coefficient will be computed.\n",
        "      title : str, optional\n",
        "          The title for the scatterplot. Default is \"Spearman Rank Correlation Scatterplot\".\n",
        "      xlabel : str, optional\n",
        "          Label for the x-axis. If None, the first column name from cols is used.\n",
        "      ylabel : str, optional\n",
        "          Label for the y-axis. If None, the second column name from cols is used.\n",
        "\n",
        "    Returns:\n",
        "      corr_coef : float\n",
        "          The computed Spearman rank correlation coefficient.\n",
        "      p_value : float\n",
        "          The p-value for testing non-correlation.\n",
        "    \"\"\"\n",
        "    if len(cols) != 2:\n",
        "        raise ValueError(\"Exactly two columns must be provided for Spearman correlation.\")\n",
        "\n",
        "    x_col, y_col = cols\n",
        "    x = df[x_col]\n",
        "    y = df[y_col]\n",
        "\n",
        "    # Calculate Spearman's rank correlation coefficient and corresponding p-value.\n",
        "    corr_coef, p_value = spearmanr(x, y)\n",
        "\n",
        "    # Setup axis labels if not provided.\n",
        "    if xlabel is None:\n",
        "        xlabel = x_col\n",
        "    if ylabel is None:\n",
        "        ylabel = y_col\n",
        "\n",
        "    # Create scatter plot.\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(x, y, alpha=0.7, c='green', edgecolors='w', s=100)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "\n",
        "    # Display the correlation coefficient on the plot.\n",
        "    plt.text(0.05, 0.95, f\"Spearman r = {corr_coef:.3f}\\np-value = {p_value:.3g}\",\n",
        "             transform=plt.gca().transAxes,\n",
        "             verticalalignment='top', bbox=dict(boxstyle=\"round\", facecolor=\"lavender\", alpha=0.5))\n",
        "\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return corr_coef, p_value"
      ],
      "metadata": {
        "id": "uNQdapbxTEtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_and_upweight_visits(df):\n",
        "    df[\"POPULARITY_BY_DAY\"] = df[\"POPULARITY_BY_DAY\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
        "\n",
        "    # Extract weekday and weekend visits\n",
        "    df[\"weekday_visits\"] = df[\"POPULARITY_BY_DAY\"].apply(lambda x: sum([x.get(day, 0) for day in [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"]]))\n",
        "    df[\"weekend_visits\"] = df[\"POPULARITY_BY_DAY\"].apply(lambda x: sum([x.get(day, 0) for day in [\"Saturday\", \"Sunday\"]]))\n",
        "\n",
        "    # Multiply by upweighting_factor\n",
        "    #df[\"weekday_visits\"] *= df[\"upweighting_factor\"]\n",
        "    #df[\"weekend_visits\"] *= df[\"upweighting_factor\"]\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "C6JNxSkseLCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/comradeshawty/patterns.git\n",
        "%cd patterns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3XoMNz9kCUD",
        "outputId": "497e5740-d50b-46fa-eaee-5ce2f0e821c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'patterns'...\n",
            "remote: Enumerating objects: 367, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 367 (delta 38), reused 0 (delta 0), pack-reused 296 (from 2)\u001b[K\n",
            "Receiving objects: 100% (367/367), 2.89 MiB | 6.41 MiB/s, done.\n",
            "Resolving deltas: 100% (199/199), done.\n",
            "/content/patterns/patterns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_income_segregation(df, cbg_gdf):\n",
        "    \"\"\"\n",
        "    For each POI (i.e. each row in df), compute an income segregation score\n",
        "    based on the processed visitor counts, and compute experienced income segregation for each CBG.\n",
        "\n",
        "    The function maps each CBG (key in the processed dict) to an income quartile\n",
        "    (using cbg_income_map, which maps CBG (as int) to a quartile in {1,2,3,4}),\n",
        "    sums the visitor counts by quartile per POI, and then calculates the POI segregation\n",
        "    measure as:\n",
        "\n",
        "         segregation = (2/3) * sum(|proportion - 0.25|)\n",
        "\n",
        "    where the proportion is the fraction of visitors from each quartile at that POI.\n",
        "\n",
        "    In addition, we compute the experienced income segregation for each CBG.\n",
        "    For each POI (denoted by α):\n",
        "      - τ₍q,α₎: the proportion of time at place α spent by income group q.\n",
        "      - For each CBG b visiting that POI, τ₍b,α₎ is calculated as the count for b at α divided by\n",
        "        the total visitors at α, but then normalized across all POIs (i.e. divided by the CBG's global total visits).\n",
        "    Then, for each CBG, the relative exposure is:\n",
        "         τ₍b,q₎ = Σ₍α visited by b₎ (τ₍b,α₎ * τ₍q,α₎)\n",
        "    and the experienced income segregation measure is:\n",
        "         Sᵢ = (2/3) * Σ₍q=1...4₎ |τ₍b,q₎ − 0.25|\n",
        "\n",
        "    Additionally, this function adds a column to df named 'quartile_proportions'\n",
        "    which contains, for each POI, a dictionary with the proportions of visitors from each income quartile.\n",
        "    The dictionary is formatted as: {'low': prop, 'lower_middle': prop, 'upper_middle': prop, 'high': prop}\n",
        "\n",
        "    Parameters:\n",
        "      df     : DataFrame that includes the 'adjusted_cbg_visitors' column containing the processed visitor counts.\n",
        "      cbg_gdf: GeoDataFrame with CBG information and an 'income_quantile' column;\n",
        "               the income labels for CBGs are in {\"low\", \"lower_middle\", \"upper_middle\", \"high\"}.\n",
        "\n",
        "    Returns:\n",
        "      Tuple: (df with added columns 'income_segregation' and 'quartile_proportions',\n",
        "              updated cbg_gdf with column 'experienced_income_segregation')\n",
        "    \"\"\"\n",
        "    income_label_to_quartile = {\"low\": 1, \"lower_middle\": 2, \"upper_middle\": 3, \"high\": 4}\n",
        "\n",
        "    # Ensure CBGs in cbg_gdf are correctly formatted.\n",
        "    cbg_gdf[\"cbg\"] = cbg_gdf[\"cbg\"].astype(str).str.lstrip(\"0\").astype(int)\n",
        "\n",
        "    # Create mapping: CBG → Income Quartile.\n",
        "    cbg_income_map = cbg_gdf.set_index(\"cbg\")[\"income_quantile\"].map(income_label_to_quartile).to_dict()\n",
        "\n",
        "    def segregation_from_dict(visitor_dict):\n",
        "        \"\"\"\n",
        "        Compute the POI-level income segregation score along with the distribution of visitor proportions by quartile.\n",
        "        Returns a tuple: (segregation score, proportions array, proportions dictionary, total visitors at the POI).\n",
        "        \"\"\"\n",
        "        quartile_counts = np.zeros(4, dtype=float)\n",
        "        for cbg, count in visitor_dict.items():\n",
        "            try:\n",
        "                cbg_int = int(cbg)\n",
        "            except Exception:\n",
        "                continue\n",
        "            quartile = cbg_income_map.get(cbg_int, None)\n",
        "            if quartile is not None:\n",
        "                quartile_counts[quartile - 1] += count  # store in 0-based index.\n",
        "\n",
        "        total = quartile_counts.sum()\n",
        "        if total == 0:\n",
        "            default_proportions = {\"low\": 0, \"lower_middle\": 0, \"upper_middle\": 0, \"high\": 0}\n",
        "            return np.nan, None, default_proportions, total\n",
        "\n",
        "        proportions = quartile_counts / total  # Fraction for each quartile.\n",
        "        segregation = (2/3) * np.sum(np.abs(proportions - 0.25))\n",
        "        proportions_dict = {\n",
        "            \"low\": proportions[0],\n",
        "            \"lower_middle\": proportions[1],\n",
        "            \"upper_middle\": proportions[2],\n",
        "            \"high\": proportions[3]\n",
        "        }\n",
        "        return segregation, proportions, proportions_dict, total\n",
        "\n",
        "    # Compute POI-level segregation scores and prepare for CBG-level aggregation.\n",
        "    poi_segregation_scores = []         # Holds segregation score for each POI.\n",
        "    quartile_proportions_list = []        # Holds the proportions dictionary for each POI.\n",
        "\n",
        "    # Dictionary to hold total visits per CBG across all POIs.\n",
        "    total_visits_per_cbg = {}\n",
        "    # Dictionary to accumulate exposure contributions per CBG; key: cbg, value: np.array (length 4)\n",
        "    cbg_exposure = {}\n",
        "\n",
        "    # First pass: calculate global total visits for each CBG across all POIs.\n",
        "    for idx, row in df.iterrows():\n",
        "        visitor_dict = row['adjusted_cbg_visitors']\n",
        "        for cbg, count in visitor_dict.items():\n",
        "            try:\n",
        "                cbg_int = int(cbg)\n",
        "            except Exception:\n",
        "                continue\n",
        "            total_visits_per_cbg[cbg_int] = total_visits_per_cbg.get(cbg_int, 0) + count\n",
        "\n",
        "    # Second pass: compute each POI's quartile proportions and accumulate CBG exposure contributions.\n",
        "    for idx, row in df.iterrows():\n",
        "        visitor_dict = row['adjusted_cbg_visitors']\n",
        "        segregation_value, proportions, proportions_dict, total_alpha = segregation_from_dict(visitor_dict)\n",
        "\n",
        "        poi_segregation_scores.append(segregation_value)\n",
        "        quartile_proportions_list.append(proportions_dict)\n",
        "\n",
        "        # For each CBG present in the POI, compute its weight for this POI and add its exposure contribution.\n",
        "        for cbg, count in visitor_dict.items():\n",
        "            try:\n",
        "                cbg_int = int(cbg)\n",
        "            except Exception:\n",
        "                continue\n",
        "            global_total = total_visits_per_cbg.get(cbg_int, 0)\n",
        "            if global_total == 0 or proportions is None:\n",
        "                continue\n",
        "            # τ₍b,α₎: fraction of the CBG's visits that occur at this POI.\n",
        "            tau_b_alpha = count / global_total\n",
        "            contribution = tau_b_alpha * proportions\n",
        "            if cbg_int in cbg_exposure:\n",
        "                cbg_exposure[cbg_int] += contribution\n",
        "            else:\n",
        "                cbg_exposure[cbg_int] = np.array(contribution, dtype=float)\n",
        "\n",
        "    # Add the computed POI-level income segregation scores and quartile proportions as new columns in df.\n",
        "    df = df.copy()\n",
        "    df['Sα'] = poi_segregation_scores\n",
        "    df['quartile_proportions'] = quartile_proportions_list\n",
        "\n",
        "    # Compute experienced income segregation for each CBG and add it to the cbg_gdf.\n",
        "    experienced_income_segregation = {}\n",
        "    for cbg, exposure_array in cbg_exposure.items():\n",
        "        exposure_sum = exposure_array.sum()\n",
        "        if exposure_sum == 0:\n",
        "            experienced_income_segregation[cbg] = np.nan\n",
        "        else:\n",
        "            normalized_exposure = exposure_array / exposure_sum\n",
        "            experienced_income_segregation[cbg] = (2/3) * np.sum(np.abs(normalized_exposure - 0.25))\n",
        "\n",
        "    cbg_gdf = cbg_gdf.copy()\n",
        "    cbg_gdf['Si'] = cbg_gdf['cbg'].map(experienced_income_segregation)\n",
        "\n",
        "    return df, cbg_gdf"
      ],
      "metadata": {
        "id": "8Km-nrD2b5Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_2010_to_2020_block_groups(expanded_df, crosswalk_df, cbg_col='cbg'):\n",
        "    expanded_df=expanded_df.merge(crosswalk_df,left_on=cbg_col,right_on='bg2010ge',how='left')\n",
        "    expanded_df.rename(columns={'bg2020ge':'cbg_2020'},inplace=True)\n",
        "    if 'geometry' in expanded_df.columns:\n",
        "        expanded_df = gpd.GeoDataFrame(expanded_df, geometry='geometry', crs=\"EPSG:4326\")\n",
        "\n",
        "    return expanded_df"
      ],
      "metadata": {
        "id": "XmiaK_ywSqMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_unique_cbg_keys(df):\n",
        "    \"\"\"\n",
        "    Given a DataFrame with an 'adjusted_cbg_visitors' column (with dictionaries as values),\n",
        "    extract a set of unique CBG keys (as integers) across all rows.\n",
        "    \"\"\"\n",
        "    unique_keys = set()\n",
        "    for visitors in df['adjusted_cbg_visitors']:\n",
        "        # Convert each key to int before adding\n",
        "        for key in visitors.keys():\n",
        "            try:\n",
        "                unique_keys.add(int(key))\n",
        "            except ValueError:\n",
        "                continue\n",
        "    return unique_keys\n",
        "\n",
        "def count_common_cbgs(cbg_gdf,crosswalk_df, unique_cbg_keys):\n",
        "    \"\"\"\n",
        "    Count how many CBGs in the 'cbg' column of cbg_gdf (converted to integers)\n",
        "    are also in unique_cbg_keys.\n",
        "    \"\"\"\n",
        "    # Ensure that the cbg column is converted to integers.\n",
        "    cbg_set = set(cbg_gdf['cbg'].astype(int))\n",
        "    cbg_2020_set=set(crosswalk_df['GEOID_BLKGRP_20'].astype(int))\n",
        "    common = cbg_set.intersection(cbg_2020_set)\n",
        "    common_2020 = unique_cbg_keys.intersection(cbg_2020_set)\n",
        "    return len(common), common,common_2020,len(common_2020)"
      ],
      "metadata": {
        "id": "_OcpnZxaS4Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_quintile_income_segregation(df, cbg_gdf):\n",
        "    \"\"\"\n",
        "    For each POI (i.e. each row in df), compute an income segregation score\n",
        "    based on the processed visitor counts, and compute experienced income segregation for each CBG.\n",
        "\n",
        "    The function maps each CBG (key in the processed dict) to an income quintile\n",
        "    (using cbg_income_map, which maps CBG (as int) to a quartile in {1,2,3,4,5}),\n",
        "    sums the visitor counts by quartile per POI, and then calculates the POI segregation\n",
        "    measure as:\n",
        "\n",
        "         segregation = (5/8) * sum(|proportion - 0.2|)\n",
        "\n",
        "    where the proportion is the fraction of visitors from each quartile at that POI.\n",
        "\n",
        "    In addition, we compute the experienced income segregation for each CBG.\n",
        "    For each POI (denoted by α):\n",
        "      - τ₍q,α₎: the proportion of time at place α spent by income group q.\n",
        "      - For each CBG b visiting that POI, τ₍b,α₎ is calculated as the count for b at α divided by\n",
        "        the total visitors at α, but then normalized across all POIs (i.e. divided by the CBG's global total visits).\n",
        "    Then, for each CBG, the relative exposure is:\n",
        "         τ₍b,q₎ = Σ₍α visited by b₎ (τ₍b,α₎ * τ₍q,α₎)\n",
        "    and the experienced income segregation measure is:\n",
        "         Sᵢ = (5/8) * Σ₍q=1...5₎ |τ₍b,q₎ − 0.2|\n",
        "\n",
        "    Additionally, this function adds a column to df named 'quintile_proportions'\n",
        "    which contains, for each POI, a dictionary with the proportions of visitors from each income quintile.\n",
        "    The dictionary is formatted as: {'low': prop, 'lower_middle': prop, 'middle':prop,'upper_middle': prop, 'high': prop}\n",
        "\n",
        "    Parameters:\n",
        "      df     : DataFrame that includes the 'adjusted_cbg_visitors' column containing the processed visitor counts.\n",
        "      cbg_gdf: GeoDataFrame with CBG information and an 'income_quintile' column;\n",
        "               the income labels for CBGs are in {\"low\", \"lower_middle\", \"middle\",\"upper_middle\", \"high\"}.\n",
        "\n",
        "    Returns:\n",
        "      Tuple: (df with added columns 'quintile_income_segregation' and 'quintile_proportions',\n",
        "              updated cbg_gdf with column 'experienced_income_segregation')\n",
        "    \"\"\"\n",
        "    income_label_to_quintile = {\"low\": 1, \"lower_middle\": 2,\"middle\":3, \"upper_middle\": 4, \"high\": 5}\n",
        "\n",
        "    # Ensure CBGs in cbg_gdf are correctly formatted.\n",
        "    cbg_gdf[\"cbg\"] = cbg_gdf[\"cbg\"].astype(str).str.lstrip(\"0\").astype(int)\n",
        "\n",
        "    # Create mapping: CBG → Income Quartile.\n",
        "    cbg_income_map = cbg_gdf.set_index(\"cbg\")[\"income_quintile\"].map(income_label_to_quintile).to_dict()\n",
        "\n",
        "    def segregation_from_dict(visitor_dict):\n",
        "        \"\"\"\n",
        "        Compute the POI-level income segregation score along with the distribution of visitor proportions by quartile.\n",
        "        Returns a tuple: (segregation score, proportions array, proportions dictionary, total visitors at the POI).\n",
        "        \"\"\"\n",
        "        quintile_counts = np.zeros(5, dtype=float)\n",
        "        for cbg, count in visitor_dict.items():\n",
        "            try:\n",
        "                cbg_int = int(cbg)\n",
        "            except Exception:\n",
        "                continue\n",
        "            quintile = cbg_income_map.get(cbg_int, None)\n",
        "            if quintile is not None:\n",
        "                quintile_counts[quintile - 1] += count  # store in 0-based index.\n",
        "\n",
        "        total = quintile_counts.sum()\n",
        "        if total == 0:\n",
        "            default_proportions = {\"low\": 0, \"lower_middle\": 0, \"middle\":0,\"upper_middle\": 0, \"high\": 0}\n",
        "            return np.nan, None, default_proportions, total\n",
        "\n",
        "        proportions = quintile_counts / total  # Fraction for each quartile.\n",
        "        segregation = (5/8) * np.sum(np.abs(proportions - 0.2))\n",
        "        proportions_dict = {\n",
        "            \"low\": proportions[0],\n",
        "            \"lower_middle\": proportions[1],\n",
        "            \"middle\":proportions[2],\n",
        "            \"upper_middle\": proportions[3],\n",
        "            \"high\": proportions[4]\n",
        "        }\n",
        "        return segregation, proportions, proportions_dict, total\n",
        "\n",
        "    # Compute POI-level segregation scores and prepare for CBG-level aggregation.\n",
        "    poi_segregation_scores = []         # Holds segregation score for each POI.\n",
        "    quintile_proportions_list = []        # Holds the proportions dictionary for each POI.\n",
        "\n",
        "    # Dictionary to hold total visits per CBG across all POIs.\n",
        "    total_visits_per_cbg = {}\n",
        "    # Dictionary to accumulate exposure contributions per CBG; key: cbg, value: np.array (length 5)\n",
        "    cbg_exposure = {}\n",
        "\n",
        "    # First pass: calculate global total visits for each CBG across all POIs.\n",
        "    for idx, row in df.iterrows():\n",
        "        visitor_dict = row['adjusted_cbg_visitors']\n",
        "        for cbg, count in visitor_dict.items():\n",
        "            try:\n",
        "                cbg_int = int(cbg)\n",
        "            except Exception:\n",
        "                continue\n",
        "            total_visits_per_cbg[cbg_int] = total_visits_per_cbg.get(cbg_int, 0) + count\n",
        "\n",
        "    # Second pass: compute each POI's quartile proportions and accumulate CBG exposure contributions.\n",
        "    for idx, row in df.iterrows():\n",
        "        visitor_dict = row['adjusted_cbg_visitors']\n",
        "        segregation_value, proportions, proportions_dict, total_alpha = segregation_from_dict(visitor_dict)\n",
        "\n",
        "        poi_segregation_scores.append(segregation_value)\n",
        "        quintile_proportions_list.append(proportions_dict)\n",
        "\n",
        "        # For each CBG present in the POI, compute its weight for this POI and add its exposure contribution.\n",
        "        for cbg, count in visitor_dict.items():\n",
        "            try:\n",
        "                cbg_int = int(cbg)\n",
        "            except Exception:\n",
        "                continue\n",
        "            global_total = total_visits_per_cbg.get(cbg_int, 0)\n",
        "            if global_total == 0 or proportions is None:\n",
        "                continue\n",
        "            # τ₍b,α₎: fraction of the CBG's visits that occur at this POI.\n",
        "            tau_b_alpha = count / global_total\n",
        "            contribution = tau_b_alpha * proportions\n",
        "            if cbg_int in cbg_exposure:\n",
        "                cbg_exposure[cbg_int] += contribution\n",
        "            else:\n",
        "                cbg_exposure[cbg_int] = np.array(contribution, dtype=float)\n",
        "\n",
        "    # Add the computed POI-level income segregation scores and quartile proportions as new columns in df.\n",
        "    df = df.copy()\n",
        "    df['Sα_q'] = poi_segregation_scores\n",
        "    df['quintile_proportions'] = quintile_proportions_list\n",
        "\n",
        "    # Compute experienced income segregation for each CBG and add it to the cbg_gdf.\n",
        "    experienced_income_segregation = {}\n",
        "    for cbg, exposure_array in cbg_exposure.items():\n",
        "        exposure_sum = exposure_array.sum()\n",
        "        if exposure_sum == 0:\n",
        "            experienced_income_segregation[cbg] = np.nan\n",
        "        else:\n",
        "            normalized_exposure = exposure_array / exposure_sum\n",
        "            experienced_income_segregation[cbg] = (5/8) * np.sum(np.abs(normalized_exposure - 0.2))\n",
        "\n",
        "    cbg_gdf = cbg_gdf.copy()\n",
        "    cbg_gdf['Si_q'] = cbg_gdf['cbg'].map(experienced_income_segregation)\n",
        "\n",
        "    return df, cbg_gdf"
      ],
      "metadata": {
        "id": "Ts6s6QvAIO2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_residential_income_segregation(cbg_gdf):\n",
        "    \"\"\"\n",
        "    Computes S_res (residential income segregation) for each CBG using\n",
        "    fixed bracket definitions for 'low', 'lower_middle', 'upper_middle', 'high'.\n",
        "\n",
        "    Each row of cbg_gdf is expected to have columns representing the\n",
        "    number of households in these brackets:\n",
        "      'less_than_10k', '10k_15k', '15k_to_20k', '20k_to_25k', '25k_to_30k',\n",
        "      '30k_to_35k', '35k_to_40k', '40k_to_45k', '45k_to_50k', '50k_to_60k',\n",
        "      '60k_to_75k', '75k_to_100k', '100k_to_125k', '125k_to_150k',\n",
        "      '150k_to_200k', '200k_or_more'.\n",
        "\n",
        "    The category definitions (from bracket to income group) are:\n",
        "      low =  { 'less_than_10k', '10k_15k', '15k_to_20k' }\n",
        "      lower_middle = { '20k_to_25k', '25k_to_30k', '30k_to_35k', '35k_to_40k', '40k_to_45k', '45k_to_50k' }\n",
        "      upper_middle = { '50k_to_60k', '60k_to_75k', '75k_to_100k' }\n",
        "      high = { '100k_to_125k', '125k_to_150k', '150k_to_200k', '200k_or_more' }\n",
        "\n",
        "    We define the segregation measure using four quartiles:\n",
        "      S_res = (2/3) * sum( | proportion_in_quartile - 0.25 | ) over all quartiles.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    cbg_gdf : DataFrame (or GeoDataFrame)\n",
        "        Must have the columns for each bracket listed above.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    cbg_gdf : DataFrame (copy)\n",
        "        A modified copy of the original with an added column \"S_res\" that holds\n",
        "        the computed segregation measure per CBG.\n",
        "    \"\"\"\n",
        "\n",
        "    # Mapping from bracket columns to quartile category\n",
        "    bracket_map = {\n",
        "        'low': ['less_than_10k', '10k_15k', '15k_to_20k'],\n",
        "        'lower_middle': ['20k_to_25k', '25k_to_30k', '30k_to_35k','35k_to_40k', '40k_to_45k', '45k_to_50k'],\n",
        "        'upper_middle': ['50k_to_60k', '60k_to_75k', '75k_to_100k'],\n",
        "        'high': ['100k_to_125k', '125k_to_150k','150k_to_200k', '200k_or_more']}\n",
        "\n",
        "    def compute_s_res_for_row(row):\n",
        "        q_pops = []\n",
        "        total_pop = 0.0\n",
        "        for category in ['low', 'lower_middle', 'upper_middle', 'high']:\n",
        "            cat_sum = 0.0\n",
        "            for bracket_col in bracket_map[category]:\n",
        "                cat_sum += float(row.get(bracket_col, 0.0))\n",
        "            q_pops.append(cat_sum)\n",
        "            total_pop += cat_sum\n",
        "\n",
        "        if total_pop == 0:\n",
        "            return np.nan\n",
        "\n",
        "        proportions = [pop / total_pop for pop in q_pops]\n",
        "        s_res = (2.0 / 3.0) * sum(abs(p - 0.25) for p in proportions)\n",
        "        return s_res\n",
        "\n",
        "    new_gdf = cbg_gdf.copy()\n",
        "    new_gdf[\"S_res\"] = new_gdf.apply(compute_s_res_for_row, axis=1)\n",
        "    new_gdf.dropna(subset=['Si','S_res'],inplace=True,ignore_index=True)\n",
        "    return new_gdf"
      ],
      "metadata": {
        "id": "5qIoiVbAPFiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_place_entropy(df, cbg_gdf):\n",
        "    \"\"\"\n",
        "    For each place (each row in df), compute an entropy measure Hₐ that quantifies\n",
        "    the unevenness of the distribution of visitor groups (income quartiles in this case).\n",
        "\n",
        "    The entropy is defined as:\n",
        "\n",
        "         Hₐ = - ( Σ₍q=1 to 4₎ τ₍q,α₎ log(τ₍q,α₎) ) / log(4)\n",
        "\n",
        "    where τ₍q,α₎ is the fraction of visitors at place α from income quartile q.\n",
        "    When the groups are equally present (τ = 1/4 for every group), then Hₐ = 1.\n",
        "    When only one group visits (one τ is 1 and the rest 0), then Hₐ = 0.\n",
        "\n",
        "    This function adapts the compute_income_segregation function from income_segregation.py\n",
        "    by aggregating visitor counts (from the 'adjusted_cbg_visitors' column in df) by\n",
        "    the income quartile of each CBG (based on the cbg_gdf's 'income_quantile' column) and\n",
        "    computing the entropy of the distribution.\n",
        "\n",
        "    Parameters:\n",
        "      df     : DataFrame that includes the column 'adjusted_cbg_visitors' where each value\n",
        "               is a dictionary mapping CBG (as a string or int) to visitor counts.\n",
        "      cbg_gdf: DataFrame (or GeoDataFrame) with CBG information, including at least two columns:\n",
        "               - 'cbg': unique identifier for each CBG.\n",
        "               - 'income_quantile': income quartile label, one of {\"low\", \"lower_middle\", \"upper_middle\", \"high\"}.\n",
        "\n",
        "    Returns:\n",
        "      df : A copy of the original df with an added column 'entropy_measure' containing Hₐ for each place.\n",
        "    \"\"\"\n",
        "    income_label_to_quartile = {\n",
        "        \"low\": 1,\n",
        "        \"lower_middle\": 2,\n",
        "        \"upper_middle\": 3,\n",
        "        \"high\": 4\n",
        "    }\n",
        "\n",
        "    cbg_gdf = cbg_gdf.copy()\n",
        "    cbg_gdf[\"cbg\"] = cbg_gdf[\"cbg\"].astype(str).str.lstrip(\"0\").astype(int)\n",
        "\n",
        "    cbg_income_map = cbg_gdf.set_index(\"cbg\")[\"income_quantile\"].map(income_label_to_quartile).to_dict()\n",
        "\n",
        "    def entropy_from_dict(visitor_dict):\n",
        "        \"\"\"\n",
        "        For a given visitor dictionary from adjusted_cbg_visitors, aggregate visitor counts by income quartile,\n",
        "        compute the quantified proportions, and then calculate the entropy measure Hₐ.\n",
        "        \"\"\"\n",
        "        quartile_counts = np.zeros(4, dtype=float)  # indices 0 through 3 correspond to quartiles 1 to 4\n",
        "        for cbg, count in visitor_dict.items():\n",
        "            try:\n",
        "                cbg_int = int(cbg)\n",
        "            except Exception:\n",
        "                continue\n",
        "            quartile = cbg_income_map.get(cbg_int, None)\n",
        "            if quartile is not None:\n",
        "                quartile_counts[quartile - 1] += count\n",
        "\n",
        "        total = quartile_counts.sum()\n",
        "        if total == 0:\n",
        "            return np.nan\n",
        "\n",
        "        # Compute proportions τ₍q,α₎ for each quartile\n",
        "        proportions = quartile_counts / total\n",
        "\n",
        "        # Compute the entropy measure\n",
        "        # Handle p = 0 by using 0 * log(p) = 0.\n",
        "        entropy_sum = 0.0\n",
        "        for p in proportions:\n",
        "            if p > 0:\n",
        "                entropy_sum += p * np.log(p)\n",
        "        # Normalize entropy to be between 0 and 1.\n",
        "        H = - entropy_sum / np.log(4)\n",
        "        return H\n",
        "\n",
        "    # Compute the entropy measure for each place (i.e. each row in df)\n",
        "    df = df.copy()\n",
        "    df[\"Hα\"] = df[\"adjusted_cbg_visitors\"].apply(entropy_from_dict)\n",
        "    return df"
      ],
      "metadata": {
        "id": "HHjWbFm8hnjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_out_of_cbg_visitors(mp):\n",
        "  def calc_out_of_cbg_visitors(row):\n",
        "          visitors = row.get('adjusted_cbg_visitors', {})\n",
        "          # Ensure the POI_CBG is treated as a string for comparison\n",
        "          poi_cbg = str(row.get('POI_CBG', ''))\n",
        "          total = 0\n",
        "          for cbg, count in visitors.items():\n",
        "              # Compare keys as strings to ensure consistency\n",
        "              if str(cbg) != poi_cbg:\n",
        "                  total += count\n",
        "          return total\n",
        "  mp = mp.copy()\n",
        "  mp['out_of_cbg_visitors'] = mp.apply(calc_out_of_cbg_visitors, axis=1)\n",
        "  return mp"
      ],
      "metadata": {
        "id": "xKmtIuwwpxXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_avg_dwell(stops_mp):\n",
        "  if stops_mp['BUCKETED_DWELL_TIMES'].dtype == object and stops_mp['BUCKETED_DWELL_TIMES'].apply(lambda x: isinstance(x, str)).all():\n",
        "      stops_mp['BUCKETED_DWELL_TIMES'] = stops_mp['BUCKETED_DWELL_TIMES'].apply(ast.literal_eval)\n",
        "\n",
        "  buckets = [\"<5\", \"5-20\", \"21-60\", \"61-240\", \">240\"]\n",
        "  rep_values = np.array([2.5, 12.5, 40.5, 150, 300])  # Representative dwell times\n",
        "  for bucket in buckets:\n",
        "      stops_mp[bucket] = stops_mp[\"BUCKETED_DWELL_TIMES\"].str.get(bucket).fillna(0)\n",
        "\n",
        "  counts = stops_mp[buckets]\n",
        "\n",
        "  weighted_sum = (counts * rep_values).sum(axis=1)\n",
        "  total_weighted_count = counts.sum(axis=1)\n",
        "  stops_mp[\"weighted_avg_dwell_time\"] = np.where(total_weighted_count > 0, weighted_sum / total_weighted_count, np.nan)\n",
        "  return stops_mp"
      ],
      "metadata": {
        "id": "6KjqCM-8uyoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_mp():\n",
        "  mptemp=mp.copy()\n",
        "  mptemp.drop(columns='geometry',inplace=True)\n",
        "  mptemp.to_csv('/content/drive/MyDrive/data/final_mp.csv',index=False)"
      ],
      "metadata": {
        "id": "dcPR9dJPtSRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kde_twocols(stops_mp, col1, col2):\n",
        "  sns.set_style(\"whitegrid\")\n",
        "\n",
        "  # Plot KDE\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  sns.kdeplot(stops_mp[col1], label=col1, fill=True, alpha=0.5)\n",
        "  sns.kdeplot(stops_mp[col2], label=col2, fill=True, alpha=0.5)\n",
        "\n",
        "  # Labels and title\n",
        "  plt.xlabel(\"Time (minutes)\")\n",
        "  plt.ylabel(\"Density\")\n",
        "  plt.title(f\"KDE of {col1} and {col2}\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "TUDOhQKLybsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def temp(stops_mp):\n",
        "\n",
        "\n",
        "  def safe_convert(value):\n",
        "      \"\"\"Convert string representation of lists/dicts into actual lists/dicts.\"\"\"\n",
        "      if isinstance(value, str):\n",
        "          try:\n",
        "              return ast.literal_eval(value)  # Convert to list or dict\n",
        "          except:\n",
        "              return np.nan  # If conversion fails, return NaN\n",
        "      return value\n",
        "\n",
        "  # Apply conversion to necessary columns\n",
        "  for col in ['adjusted_visits_by_day', 'stops_by_day', 'stops_by_day_of_week', 'POPULARITY_BY_DAY','stops_by_hour','POPULARITY_BY_HOUR']:\n",
        "      stops_mp[col] = stops_mp[col].apply(safe_convert)\n",
        "\n",
        "  # Convert stops_by_hour and POPULARITY_BY_HOUR lists to their sum\n",
        "  stops_mp['stops_by_hour'] = stops_mp['stops_by_hour'].apply(lambda x: np.sum(x) if isinstance(x, list) else np.nan)\n",
        "  stops_mp['POPULARITY_BY_HOUR'] = stops_mp['POPULARITY_BY_HOUR'].apply(lambda x: np.sum(x) if isinstance(x, list) else np.nan)\n",
        "\n",
        "  # Convert adjusted_visits_by_day and stops_by_day lists to their sum\n",
        "  stops_mp['adjusted_visits_by_day'] = stops_mp['adjusted_visits_by_day'].apply(lambda x: np.sum(x) if isinstance(x, list) else np.nan)\n",
        "  stops_mp['stops_by_day'] = stops_mp['stops_by_day'].apply(lambda x: np.sum(x) if isinstance(x, list) else np.nan)\n",
        "\n",
        "  # Normalize stops_by_day_of_week to match POPULARITY_BY_DAY format\n",
        "  def normalize_day_keys(stops_dict):\n",
        "      \"\"\"Reformat stops_by_day_of_week to match POPULARITY_BY_DAY structure.\"\"\"\n",
        "      if isinstance(stops_dict, dict):\n",
        "          corrected_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
        "          corrected_dict = {day: stops_dict.get(day.lower(), 0) for day in corrected_order}  # Normalize keys\n",
        "          return list(corrected_dict.values())  # Convert back to list format\n",
        "      return np.nan\n",
        "\n",
        "  stops_mp['stops_by_day_of_week'] = stops_mp['stops_by_day_of_week'].apply(normalize_day_keys)\n",
        "  stops_mp['POPULARITY_BY_DAY'] = stops_mp['POPULARITY_BY_DAY'].apply(lambda x: list(x.values()) if isinstance(x, dict) else np.nan)\n",
        "\n",
        "  # Function to compute correlation safely\n",
        "  def compute_correlation(x, y):\n",
        "      x, y = x.dropna().reset_index(drop=True), y.dropna().reset_index(drop=True)\n",
        "      if len(x) > 1 and len(y) > 1 and len(x) == len(y):\n",
        "          return np.corrcoef(x, y)[0, 1]\n",
        "      else:\n",
        "          return np.nan  # Return NaN if not enough valid data\n",
        "\n",
        "  # Compute correlations\n",
        "  correlations = {\n",
        "      \"adjusted_visits_by_day vs. stops_by_day\": compute_correlation(stops_mp['adjusted_visits_by_day'], stops_mp['stops_by_day']),\n",
        "      \"stops_by_hour vs. POPULARITY_BY_HOUR\": compute_correlation(stops_mp['stops_by_hour'], stops_mp['POPULARITY_BY_HOUR']),\n",
        "      \"POPULARITY_BY_DAY vs. stops_by_day_of_week\": compute_correlation(\n",
        "          pd.Series(np.concatenate(stops_mp['POPULARITY_BY_DAY'].dropna().values)),\n",
        "          pd.Series(np.concatenate(stops_mp['stops_by_day_of_week'].dropna().values))\n",
        "      )\n",
        "  }\n",
        "\n",
        "  # Print correlation results\n",
        "  print(\"Correlations:\")\n",
        "  for key, value in correlations.items():\n",
        "      print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "  # Plot scatterplots\n",
        "  plt.figure(figsize=(12, 4))\n",
        "\n",
        "  # Scatterplot: adjusted_visits_by_day vs. stops_by_day\n",
        "  plt.subplot(1, 3, 1)\n",
        "  plt.scatter(stops_mp['adjusted_visits_by_day'], stops_mp['stops_by_day'], alpha=0.5)\n",
        "  plt.xlabel(\"Adjusted Visits by Day\")\n",
        "  plt.ylabel(\"Stops by Day\")\n",
        "  plt.title(\"Scatterplot: Adjusted Visits vs. Stops by Day\")\n",
        "\n",
        "  # Scatterplot: stops_by_hour vs. POPULARITY_BY_HOUR\n",
        "  plt.subplot(1, 3, 2)\n",
        "  plt.scatter(stops_mp['stops_by_hour'], stops_mp['POPULARITY_BY_HOUR'], alpha=0.5)\n",
        "  plt.xlabel(\"Stops by Hour\")\n",
        "  plt.ylabel(\"Popularity by Hour\")\n",
        "  plt.title(\"Scatterplot: Stops by Hour vs. Popularity\")\n",
        "\n",
        "  # Scatterplot: POPULARITY_BY_DAY vs. stops_by_day_of_week\n",
        "  plt.subplot(1, 3, 3)\n",
        "  plt.scatter(\n",
        "      np.concatenate(stops_mp['POPULARITY_BY_DAY'].dropna().values).flatten(),\n",
        "      np.concatenate(stops_mp['stops_by_day_of_week'].dropna().values).flatten(),\n",
        "      alpha=0.5\n",
        "  )\n",
        "  plt.xlabel(\"Popularity by Day\")\n",
        "  plt.ylabel(\"Stops by Day of Week\")\n",
        "  plt.title(\"Scatterplot: Popularity by Day vs. Stops by Day\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "5zqrBpzb0KCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CrOLbCN-7SyM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "import random\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Polygon,Point\n",
        "import numpy as np\n",
        "import regex as re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import pearsonr\n",
        "from collections import Counter\n",
        "import math\n",
        "from scipy.spatial import cKDTree\n",
        "from scipy.stats import spearmanr\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import ast\n",
        "from ast import literal_eval\n",
        "from cbgs_processor import compute_racial_weighted_mean,compute_income_weighted_mean,compute_racial_visitor_counts,compute_weighted_mean,compute_racial_visitor_counts,normalize_cbg_data,compute_exact_visitor_counts\n",
        "from income_segregation import compute_residential_income_segregation,compute_income_segregation,get_income_data,calculate_income_quintiles_cbsa,compute_quintile_income_segregation\n",
        "from helpers import load_data\n",
        "from racial_segregation import compute_racial_segregation_with_exposure,get_racial_data,compute_racial_segregation_with_cbsa_baseline\n",
        "#segments_gdf=gpd.read_file('/content/drive/MyDrive/data/segments_gdf.geojson')\n",
        "#route_stats=pd.read_csv('/content/drive/MyDrive/data/route_stats.csv')\n",
        "#spend=pd.read_csv('/content/drive/MyDrive/data/brh_sp_2023.csv')\n",
        "nwd=gpd.read_file('/content/drive/MyDrive/data/nwd/NationalWalkabilityIndex.shp')\n",
        "stops_mp=pd.read_csv('/content/drive/MyDrive/data/stops_mp.csv')\n",
        "mp, cbg_gdf,brh_np=load_data()\n",
        "cbg_gdf['no_veh_pop']=cbg_gdf['no_veh_renter']+cbg_gdf['no_veh_owner']\n",
        "#mp=pd.read_csv('/content/drive/MyDrive/data/mp.csv')\n",
        "cbg_gdf=normalize_cbg_data(cbg_gdf)\n",
        "mp=compute_racial_weighted_mean(mp,cbg_gdf)\n",
        "mp=compute_income_weighted_mean(mp,cbg_gdf)\n",
        "\n",
        "#mp = compute_racial_visitor_counts(mp, 'weighted_means', 'visitor_counts_cbg_scaled')\n",
        "#mp = compute_exact_visitor_counts(mp, 'weighted_means', 'RAW_VISITOR_COUNTS', 'no_veh_renter_frac', 'no_veh_renters')\n",
        "#mp = compute_exact_visitor_counts(mp, 'weighted_means', 'RAW_VISITOR_COUNTS', 'no_veh_owner_frac', 'no_veh_owners')\n",
        "#mp['visitors_w_no_car'] = mp['no_veh_renters'] + mp['no_veh_owners']\n",
        "#mp = compute_exact_visitor_counts(mp, 'weighted_means', 'RAW_VISITOR_COUNTS', 'with_disability_frac', 'visitors_w_disability')\n",
        "#mp = compute_exact_visitor_counts(mp, 'weighted_means', 'RAW_VISITOR_COUNTS', 'below_poverty_frac', 'visitors_below_poverty')\n",
        "#mp = compute_exact_visitor_counts(mp, 'weighted_means', 'RAW_VISITOR_COUNTS', 'commuting_pop_frac', 'commuting_visitors')\n",
        "#mp = compute_exact_visitor_counts(mp, 'weighted_means', 'RAW_VISITOR_COUNTS', 'unemployment_p', 'unemployed_visitors')\n",
        "nwd['GEOID10']=nwd['GEOID10'].astype(str).str.lstrip(\"0\").astype(int)\n",
        "nwd['GEOID20']=nwd['GEOID20'].astype(str).str.lstrip(\"0\").astype(int)\n",
        "mp['POI_CBG']=mp['POI_CBG'].astype(str).str.lstrip(\"0\").astype(int)\n",
        "mp,cbg_gdf=compute_income_segregation(mp,cbg_gdf)\n",
        "mp,cbg_gdf=compute_racial_segregation_with_exposure(mp,cbg_gdf)\n",
        "mp=extract_and_upweight_visits(mp)\n",
        "cbg_gdf = compute_residential_income_segregation(cbg_gdf)\n",
        "brh_np[\"AREA\"] = brh_np[\"AREA\"].astype(str).str.lstrip(\"0\").astype(int)\n",
        "cbg_gdf[\"cbg\"] = cbg_gdf[\"cbg\"].astype(str).str.lstrip(\"0\").astype(int)\n",
        "mp['POI_CBG']=mp['POI_CBG'].astype(str).str.lstrip(\"0\").astype(int)\n",
        "cbg_gdf = cbg_gdf.loc[:, ~cbg_gdf.columns.str.startswith(('poi_count', 'Median'))]\n",
        "cbg_gdf['upweighting_factor']=cbg_gdf['tot_pop']/(1e-9+cbg_gdf['number_devices_residing'])\n",
        "mp=mp.merge(cbg_gdf[['cbg','income_quantile','upweighting_factor']],left_on='POI_CBG',right_on='cbg',how='left')\n",
        "mp['adjusted_cbg_visitors_str']=mp['adjusted_cbg_visitors'].astype(str)\n",
        "mp['place_category'] = mp['place_category'].str.strip()\n",
        "mp['place_subcategory'] = mp['place_subcategory'].str.strip()\n",
        "mp['adjusted_cbg_visitors_str'] = mp['adjusted_cbg_visitors_str'].str.strip()\n",
        "mp.drop_duplicates(subset=['adjusted_cbg_visitors_str','place_category'], keep='first', inplace=True)\n",
        "priority_categories = {\n",
        "    'Arts and Culture', 'Retail for Basic Necessities', 'Healthcare',\n",
        "    'Restaurants', 'Sports and Exercise', 'City/Outdoors',\n",
        "    'Religious Organizations', 'Social Support',\n",
        "    'Coffee Shops, Snacks & Bakeries', 'College', 'Entertainment',\n",
        "    'Transportation', 'School'}\n",
        "\n",
        "mp = mp.sort_values(by=[\"adjusted_cbg_visitors_str\", \"place_category\"], ascending=True)\n",
        "def custom_deduplication(group):\n",
        "    priority_rows = group[group[\"place_category\"].isin(priority_categories)]\n",
        "\n",
        "    if not priority_rows.empty:\n",
        "        return priority_rows.iloc[[0]]\n",
        "    else:\n",
        "        return group.iloc[[0]]\n",
        "\n",
        "mp = mp.groupby(\"adjusted_cbg_visitors_str\", group_keys=False).apply(custom_deduplication)\n",
        "mp = mp.reset_index(drop=True)\n",
        "mp.drop(columns=['adjusted_cbg_visitors_str'],inplace=True)\n",
        "mp=mp.sort_values(by='RAW_VISITOR_COUNTS',ascending=False)\n",
        "mp.reset_index(drop=True,inplace=True)\n",
        "mask = (mp[\"merged_flag\"] == True) & (mp[\"BRANDS\"].notna())\n",
        "mp.loc[mask, \"LOCATION_NAME\"] = mp.loc[mask, \"BRANDS\"]\n",
        "mp.dropna(subset='Sα',inplace=True,ignore_index=True)\n",
        "mp=compute_out_of_cbg_visitors(mp)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import ast\n",
        "\n",
        "# Ensure POPULARITY_BY_HOUR is a list\n",
        "def safe_convert_to_list(value):\n",
        "    if isinstance(value, str):  # Convert only if it's a string\n",
        "        return ast.literal_eval(value)\n",
        "    return value  # Return as-is if already a list\n",
        "\n",
        "# Ensure POPULARITY_BY_DAY is a dictionary\n",
        "def safe_convert_to_dict(value):\n",
        "    if isinstance(value, str):  # Convert only if it's a string\n",
        "        return ast.literal_eval(value)\n",
        "    return value  # Return as-is if already a dictionary\n",
        "\n",
        "# Apply the conversion safely\n",
        "mp['POPULARITY_BY_HOUR'] = mp['POPULARITY_BY_HOUR'].apply(safe_convert_to_list)\n",
        "mp['POPULARITY_BY_DAY'] = mp['POPULARITY_BY_DAY'].apply(safe_convert_to_dict)\n",
        "\n",
        "# Multiply each entry in POPULARITY_BY_HOUR by upweighting_factor (vectorized)\n",
        "mp['POPULARITY_BY_HOUR'] = mp.apply(lambda row: (np.array(row['POPULARITY_BY_HOUR']) * row['upweighting_factor']).tolist()\n",
        "                                    if isinstance(row['POPULARITY_BY_HOUR'], list) else row['POPULARITY_BY_HOUR'], axis=1)\n",
        "\n",
        "# Multiply each entry in POPULARITY_BY_DAY by upweighting_factor (vectorized)\n",
        "mp['POPULARITY_BY_DAY'] = mp.apply(lambda row: {k: v * row['upweighting_factor'] for k, v in row['POPULARITY_BY_DAY'].items()}\n",
        "                                   if isinstance(row['POPULARITY_BY_DAY'], dict) else row['POPULARITY_BY_DAY'], axis=1)\n",
        "mp[['POPULARITY_BY_HOUR','POPULARITY_BY_DAY']]\n",
        "import numpy as np\n",
        "\n",
        "# Round up each entry in POPULARITY_BY_HOUR (vectorized)\n",
        "mp['POPULARITY_BY_HOUR'] = mp.apply(lambda row: np.ceil(row['POPULARITY_BY_HOUR']).astype(int).tolist()\n",
        "                                    if isinstance(row['POPULARITY_BY_HOUR'], list) else row['POPULARITY_BY_HOUR'], axis=1)\n",
        "\n",
        "# Round up each entry in POPULARITY_BY_DAY (vectorized)\n",
        "mp['POPULARITY_BY_DAY'] = mp.apply(lambda row: {k: int(np.ceil(v)) for k, v in row['POPULARITY_BY_DAY'].items()}\n",
        "                                   if isinstance(row['POPULARITY_BY_DAY'], dict) else row['POPULARITY_BY_DAY'], axis=1)\n",
        "mp['adjusted_cbg_visitors'] = mp.apply(lambda row: {k: int(np.ceil(v)) for k, v in row['adjusted_cbg_visitors'].items()}\n",
        "                                   if isinstance(row['adjusted_cbg_visitors'], dict) else row['adjusted_cbg_visitors'], axis=1)\n",
        "save_mp()"
      ],
      "metadata": {
        "id": "yrZG2kJCsxSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stops_mp.to_csv('/content/drive/MyDrive/data/stops_mp.csv',index=False)"
      ],
      "metadata": {
        "id": "U_MEjbabeWt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import ast\n",
        "\n",
        "# Function to safely convert string representations of lists/dicts\n",
        "def safe_convert(value, default):\n",
        "    if isinstance(value, str):\n",
        "        try:\n",
        "            return ast.literal_eval(value)  # Convert to list or dict\n",
        "        except:\n",
        "            return default  # If conversion fails, return a default value\n",
        "    return value if isinstance(value, (list, dict)) else default\n",
        "\n",
        "# Convert necessary columns safely\n",
        "stops_mp['adjusted_visits_by_day'] = stops_mp['adjusted_visits_by_day'].apply(lambda x: safe_convert(x, []))\n",
        "stops_mp['stops_by_day'] = stops_mp['stops_by_day'].apply(lambda x: safe_convert(x, []))\n",
        "stops_mp['stops_by_hour'] = stops_mp['stops_by_hour'].apply(lambda x: safe_convert(x, []))\n",
        "stops_mp['POPULARITY_BY_HOUR'] = stops_mp['POPULARITY_BY_HOUR'].apply(lambda x: safe_convert(x, []))\n",
        "stops_mp['stops_by_day_of_week'] = stops_mp['stops_by_day_of_week'].apply(lambda x: safe_convert(x, {}))\n",
        "stops_mp['POPULARITY_BY_DAY'] = stops_mp['POPULARITY_BY_DAY'].apply(lambda x: safe_convert(x, {}))\n",
        "\n",
        "# Time Series Plot for Adjusted Visits by Day vs Stops by Day\n",
        "dates = pd.date_range(start=\"2023-12-01\", end=\"2023-12-31\", freq=\"D\")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(dates, stops_mp['adjusted_visits_by_day'][0], label=\"Adjusted Visits by Day\", marker=\"o\")\n",
        "plt.plot(dates, stops_mp['stops_by_day'][0], label=\"Stops by Day\", marker=\"s\")\n",
        "plt.xlabel(\"Date (December 2023)\")\n",
        "plt.ylabel(\"Counts\")\n",
        "plt.title(\"Adjusted Visits by Day vs Stops by Day (December 2023)\")\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Time Series Plot for Stops by Hour vs Popularity by Hour\n",
        "hours = np.arange(24)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(hours, stops_mp['stops_by_hour'][0], label=\"Stops by Hour\", marker=\"o\")\n",
        "plt.plot(hours, stops_mp['POPULARITY_BY_HOUR'][0], label=\"Popularity by Hour\", marker=\"s\")\n",
        "plt.xlabel(\"Hour of the Day\")\n",
        "plt.ylabel(\"Counts\")\n",
        "plt.title(\"Stops by Hour vs Popularity by Hour\")\n",
        "plt.xticks(hours)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Time Series Plot for Popularity by Day vs Stops by Day\n",
        "days_of_week = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
        "\n",
        "stops_by_day_weekly = list(stops_mp['stops_by_day_of_week'][0].values())\n",
        "popularity_by_day_weekly = list(stops_mp['POPULARITY_BY_DAY'][0].values())\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(days_of_week, stops_by_day_weekly, label=\"Stops by Day of Week\", marker=\"o\")\n",
        "plt.plot(days_of_week, popularity_by_day_weekly, label=\"Popularity by Day\", marker=\"s\")\n",
        "plt.xlabel(\"Day of the Week\")\n",
        "plt.ylabel(\"Counts\")\n",
        "plt.title(\"Stops by Day vs Popularity by Day\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YdhiHqzSu9GI",
        "outputId": "db87dab9-a5b2-4d29-b0ac-417c25142682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 PLACEKEY      PARENT_PLACEKEY  \\\n",
              "0     224-222@8gk-ttq-sdv                  NaN   \n",
              "1     zzw-22m@8gk-twj-q75                  NaN   \n",
              "2     zzy-222@8gk-tpx-gtv                  NaN   \n",
              "3     225-222@8gk-tv9-cnq                  NaN   \n",
              "4     zzy-222@8gk-twj-kmk  zzy-223@8gk-twj-kmk   \n",
              "...                   ...                  ...   \n",
              "2894  223-222@8gk-tsw-tvz                  NaN   \n",
              "2895  226-222@8gk-tt9-4gk                  NaN   \n",
              "2896  226-223@8gk-tv8-mp9                  NaN   \n",
              "2897  227-223@8gm-9n5-6c5                  NaN   \n",
              "2898  zzw-225@8gm-977-rhq                  NaN   \n",
              "\n",
              "                                          LOCATION_NAME  \\\n",
              "0                                 The Summit Birmingham   \n",
              "1                                   Riverchase Galleria   \n",
              "2                                           River Ridge   \n",
              "3                   University Of Alabama At Birmingham   \n",
              "4                                  Riverchase Promenade   \n",
              "...                                                 ...   \n",
              "2894                                Church At Southside   \n",
              "2895                           Huffstutler Paint & Body   \n",
              "2896  Offices of Real Estate Agents and Brokers - 29...   \n",
              "2897                           LaCole's & Ann's Florist   \n",
              "2898                          Inland Seafood Birmingham   \n",
              "\n",
              "                                                address  \\\n",
              "0             214 Summit Blvd, Vestavia, AL 35243.0, US   \n",
              "1       2000 Riverchase Galleria, Hoover, AL, 35244, US   \n",
              "2           4606 Highway 280, Birmingham, AL, 35242, US   \n",
              "3            1720 University Blvd, Birmingham, AL 35294   \n",
              "4     1705 Montgomery Hwy Apt 1735, Hoover, AL, 3524...   \n",
              "...                                                 ...   \n",
              "2894          500 20th Ave S, Birmingham, AL, 35205, US   \n",
              "2895      712 Graymont Ave N, Birmingham, AL, 35203, US   \n",
              "2896            2911 Crescent Ave, Birmingham, AL 35209   \n",
              "2897                 1604 4th Ave N, Bessemer, AL 35020   \n",
              "2898           2700 Avenue D, Birmingham, AL, 35218, US   \n",
              "\n",
              "                                         place_category  \\\n",
              "0                                  Discretionary Retail   \n",
              "1                                  Discretionary Retail   \n",
              "2                                  Discretionary Retail   \n",
              "3                                               College   \n",
              "4                                  Discretionary Retail   \n",
              "...                                                 ...   \n",
              "2894                            Religious Organizations   \n",
              "2895                                  Personal Services   \n",
              "2896  Financial, Legal, Real Estate and Insurance Se...   \n",
              "2897                                  Personal Services   \n",
              "2898                       Retail for Basic Necessities   \n",
              "\n",
              "           place_subcategory  \\\n",
              "0                       Mall   \n",
              "1                       Mall   \n",
              "2                       Mall   \n",
              "3                 University   \n",
              "4            Shopping Center   \n",
              "...                      ...   \n",
              "2894  Religious Organization   \n",
              "2895          Auto Body Shop   \n",
              "2896      Real Estate Agents   \n",
              "2897                Florists   \n",
              "2898       Fresh Food Market   \n",
              "\n",
              "                                          CATEGORY_TAGS  MEDIAN_DWELL  \\\n",
              "0                                                   NaN          56.0   \n",
              "1                                                   NaN          61.0   \n",
              "2                                                   NaN          24.0   \n",
              "3                                            University         141.0   \n",
              "4                                                   NaN          23.0   \n",
              "...                                                 ...           ...   \n",
              "2894  Churches,Hindu Temple,Mosque,Sikh Temple,Synag...          27.0   \n",
              "2895                                         Body Shops         153.0   \n",
              "2896                                                NaN         197.0   \n",
              "2897                                                NaN          79.0   \n",
              "2898                                    Gourmet,Seafood         302.0   \n",
              "\n",
              "      weighted_median_distance_from_home  num_nearby_stops  \\\n",
              "0                            9046.647083               2.0   \n",
              "1                           12857.542473               1.0   \n",
              "2                            9826.700561               2.0   \n",
              "3                            7823.942284               3.0   \n",
              "4                           11646.996678               1.0   \n",
              "...                                  ...               ...   \n",
              "2894                          488.611927               4.0   \n",
              "2895                        19325.559535              10.0   \n",
              "2896                        47090.303353               8.0   \n",
              "2897                         6660.742492              13.0   \n",
              "2898                         6356.216984               7.0   \n",
              "\n",
              "                                        nearby_stop_ids      POI_CBG  \\\n",
              "0                                      ['2899', '2900']  10730128032   \n",
              "1                                              ['2098']  10730144081   \n",
              "2                                      ['2909', '2917']  11170303034   \n",
              "3                              ['1479', '1480', '1541']  10730045001   \n",
              "4                                              ['2099']  10730129122   \n",
              "...                                                 ...          ...   \n",
              "2894                   ['1492', '1493', '1528', '1529']  10730050002   \n",
              "2895  ['1134', '1135', '1276', '1277', '1363', '1364...  10730029003   \n",
              "2896  ['2251', '2435', '2436', '2437', '2438', '2446...  10730107022   \n",
              "2897  ['1060', '1061', '1087', '1088', '1089', '1090...  10730102002   \n",
              "2898  ['1211', '1212', '1213', '1214', '1215', '1245...  10730034003   \n",
              "\n",
              "      visitor_counts_cbg_scaled  \\\n",
              "0                 752520.499386   \n",
              "1                 533346.909139   \n",
              "2                 377023.813828   \n",
              "3                 319398.478932   \n",
              "4                 205399.851134   \n",
              "...                         ...   \n",
              "2894                 405.888953   \n",
              "2895                 124.493982   \n",
              "2896                 125.760000   \n",
              "2897                 182.390476   \n",
              "2898                 182.332067   \n",
              "\n",
              "                                 adjusted_visits_by_day  \\\n",
              "0     [52059, 48388, 27174, 40331, 40104, 39828, 276...   \n",
              "1     [33590, 33757, 29733, 17008, 18693, 20500, 203...   \n",
              "2     [16601, 19169, 16714, 20347, 11950, 19960, 195...   \n",
              "3     [29368, 27407, 25824, 27252, 27028, 26736, 263...   \n",
              "4     [9301, 8357, 8190, 8175, 8022, 8951, 8418, 110...   \n",
              "...                                                 ...   \n",
              "2894  [54, 54, 54, 81, 81, 81, 81, 81, 81, 81, 81, 8...   \n",
              "2895  [27, 36, 27, 44, 44, 27, 44, 44, 0, 27, 44, 44...   \n",
              "2896  [31, 52, 42, 52, 21, 21, 21, 52, 0, 52, 52, 21...   \n",
              "2897  [33, 33, 33, 33, 33, 50, 33, 33, 33, 50, 33, 3...   \n",
              "2898  [101, 101, 0, 81, 101, 81, 41, 101, 101, 0, 81...   \n",
              "\n",
              "                                           stops_by_day  \\\n",
              "0     [58.0, 30.0, 0.0, 58.0, 58.0, 58.0, 58.0, 58.0...   \n",
              "1     [14.0, 10.0, 0.0, 14.0, 14.0, 14.0, 14.0, 14.0...   \n",
              "2     [29.0, 15.0, 0.0, 29.0, 29.0, 29.0, 29.0, 29.0...   \n",
              "3     [52.0, 33.0, 0.0, 52.0, 52.0, 52.0, 52.0, 52.0...   \n",
              "4     [7.0, 5.0, 0.0, 7.0, 7.0, 7.0, 7.0, 7.0, 5.0, ...   \n",
              "...                                                 ...   \n",
              "2894  [68.0, 44.0, 0.0, 68.0, 68.0, 68.0, 68.0, 68.0...   \n",
              "2895  [266.0, 209.0, 0.0, 266.0, 266.0, 266.0, 266.0...   \n",
              "2896  [355.0, 219.0, 0.0, 355.0, 355.0, 355.0, 355.0...   \n",
              "2897  [306.0, 247.0, 0.0, 306.0, 306.0, 306.0, 306.0...   \n",
              "2898  [140.0, 70.0, 0.0, 140.0, 140.0, 140.0, 140.0,...   \n",
              "\n",
              "                                   stops_by_day_of_week  \\\n",
              "0     {'friday': 290.0, 'saturday': 150.0, 'monday':...   \n",
              "1     {'friday': 70.0, 'saturday': 50.0, 'monday': 5...   \n",
              "2     {'friday': 145.0, 'saturday': 75.0, 'monday': ...   \n",
              "3     {'friday': 260.0, 'saturday': 165.0, 'monday':...   \n",
              "4     {'friday': 35.0, 'saturday': 25.0, 'monday': 2...   \n",
              "...                                                 ...   \n",
              "2894  {'friday': 340.0, 'saturday': 220.0, 'monday':...   \n",
              "2895  {'friday': 1330.0, 'saturday': 1045.0, 'monday...   \n",
              "2896  {'friday': 1775.0, 'saturday': 1095.0, 'monday...   \n",
              "2897  {'friday': 1530.0, 'saturday': 1235.0, 'monday...   \n",
              "2898  {'friday': 700.0, 'saturday': 350.0, 'monday':...   \n",
              "\n",
              "                                 transit_service_period  \\\n",
              "0     {'friday': ['04:36:28', '21:57:00'], 'saturday...   \n",
              "1     {'friday': ['06:48:00', '18:58:00'], 'saturday...   \n",
              "2     {'friday': ['04:31:35', '21:42:19'], 'saturday...   \n",
              "3     {'friday': ['05:14:27', '22:05:17'], 'saturday...   \n",
              "4     {'friday': ['06:55:55', '19:00:42'], 'saturday...   \n",
              "...                                                 ...   \n",
              "2894  {'friday': ['05:28:14', '22:18:58'], 'saturday...   \n",
              "2895  {'friday': ['04:56:52', '22:06:13'], 'saturday...   \n",
              "2896  {'friday': ['06:18:21', '21:09:53'], 'saturday...   \n",
              "2897  {'friday': ['04:17:00', '22:28:00'], 'saturday...   \n",
              "2898  {'friday': ['05:31:14', '20:07:58'], 'saturday...   \n",
              "\n",
              "                                          stops_by_hour  \\\n",
              "0     [0, 0, 0, 0, 6, 2, 4, 6, 6, 6, 4, 2, 6, 6, 6, ...   \n",
              "1     [0, 0, 0, 0, 0, 0, 4, 2, 4, 0, 0, 2, 0, 0, 4, ...   \n",
              "2     [0, 0, 0, 0, 2, 2, 3, 2, 2, 3, 2, 4, 2, 2, 3, ...   \n",
              "3     [0, 0, 0, 0, 0, 2, 3, 6, 4, 6, 6, 5, 6, 6, 6, ...   \n",
              "4     [0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 1, 0, 0, 2, ...   \n",
              "...                                                 ...   \n",
              "2894  [0, 0, 0, 0, 0, 2, 4, 6, 8, 8, 8, 6, 8, 8, 6, ...   \n",
              "2895  [0, 0, 0, 0, 2, 12, 21, 27, 30, 41, 33, 29, 38...   \n",
              "2896  [0, 0, 0, 0, 0, 0, 14, 21, 39, 25, 45, 36, 40,...   \n",
              "2897  [0, 0, 0, 0, 7, 20, 34, 28, 29, 42, 37, 34, 26...   \n",
              "2898  [0, 0, 0, 0, 0, 7, 7, 19, 14, 14, 14, 16, 14, ...   \n",
              "\n",
              "      avg_time_between_stops  stop_frequency  \\\n",
              "0                  12.099225            50.0   \n",
              "1                  32.565217           300.0   \n",
              "2                  23.970543          1578.0   \n",
              "3                  12.033730           480.5   \n",
              "4                  67.839394          2626.0   \n",
              "...                      ...             ...   \n",
              "2894                9.105706            44.0   \n",
              "2895                2.277323            41.5   \n",
              "2896                1.858732            36.0   \n",
              "2897                2.217480            41.0   \n",
              "2898                4.194896            36.0   \n",
              "\n",
              "                                         median_headway  upweighting_factor  \\\n",
              "0                            [13.566666666666666, 14.5]           14.172131   \n",
              "1                                                 [5.0]           14.618182   \n",
              "2                            [59.55833333333333, 54.35]           23.153846   \n",
              "3        [38.15, 38.43333333333333, 33.858333333333334]            4.711191   \n",
              "4                                  [43.766666666666666]           16.168675   \n",
              "...                                                 ...                 ...   \n",
              "2894  [40.0, 40.0, 34.141666666666666, 34.1083333333...           28.785714   \n",
              "2895  [10.366666666666667, 10.416666666666666, 19.5,...            5.882353   \n",
              "2896  [10.2, 10.216666666666667, 10.133333333333333,...           22.955556   \n",
              "2897  [11.0, 11.0, 13.2, 13.15, 30.0, 30.0, 38.0, 38...           35.078947   \n",
              "2898  [33.81666666666667, 33.61666666666667, 33.5, 3...           27.300000   \n",
              "\n",
              "         <5   5-20  21-60  61-240  weighted_avg_dwell_time   >240  \\\n",
              "0     21110  10907  18313   25066                85.866526   8328   \n",
              "1     20002   4844   9771   15644                81.012422   5566   \n",
              "2     15637   8890   8252    5268                50.376019   2572   \n",
              "3     22749   2255   2153    7789               114.652473  14384   \n",
              "4     10014   3500   3597    1937                42.147874   1155   \n",
              "...     ...    ...    ...     ...                      ...    ...   \n",
              "2894     61      6     10       0                47.556180     12   \n",
              "2895     28     13      9      18               138.650943     38   \n",
              "2896     13      7      4      42               153.133333     24   \n",
              "2897     12      6     19      16               136.032468     24   \n",
              "2898     27      9      6      13               161.500000     47   \n",
              "\n",
              "                                  adjusted_cbg_visitors  \\\n",
              "0     {10730128032: 20168, 10730027001: 1034, 107301...   \n",
              "1     {10730144081: 17848, 10730143021: 8676, 107301...   \n",
              "2     {11170303034: 14520, 11170303441: 8240, 107301...   \n",
              "3     {10730045001: 7382, 10730049022: 7772, 1073014...   \n",
              "4     {10730143021: 3794, 10730129122: 3622, 1073014...   \n",
              "...                                                 ...   \n",
              "2894               {10730050002: 275, 10730050001: 132}   \n",
              "2895  {10730111113: 24, 10730027001: 4, 10730037003:...   \n",
              "2896                                 {11210113001: 126}   \n",
              "2897                                 {10730100012: 183}   \n",
              "2898                {10730052001: 133, 10730118043: 50}   \n",
              "\n",
              "                                      POPULARITY_BY_DAY  \\\n",
              "0     {'Monday': 127734, 'Tuesday': 131759, 'Wednesd...   \n",
              "1     {'Monday': 58108, 'Tuesday': 78471, 'Wednesday...   \n",
              "2     {'Monday': 104563, 'Tuesday': 122994, 'Wednesd...   \n",
              "3     {'Monday': 30411, 'Tuesday': 29747, 'Wednesday...   \n",
              "4     {'Monday': 29702, 'Tuesday': 39129, 'Wednesday...   \n",
              "...                                                 ...   \n",
              "2894  {'Monday': 346, 'Tuesday': 346, 'Wednesday': 2...   \n",
              "2895  {'Monday': 100, 'Tuesday': 112, 'Wednesday': 1...   \n",
              "2896  {'Monday': 414, 'Tuesday': 253, 'Wednesday': 2...   \n",
              "2897  {'Monday': 351, 'Tuesday': 351, 'Wednesday': 3...   \n",
              "2898  {'Monday': 410, 'Tuesday': 437, 'Wednesday': 3...   \n",
              "\n",
              "                                     POPULARITY_BY_HOUR  \\\n",
              "0     [4847, 2764, 4847, 2140, 3345, 6973, 10573, 31...   \n",
              "1     [8450, 5892, 4722, 6169, 4634, 6082, 9926, 122...   \n",
              "2     [7271, 3682, 3497, 2779, 3867, 3335, 13129, 33...   \n",
              "3     [11972, 5343, 7458, 6869, 7015, 8245, 18619, 1...   \n",
              "4     [1423, 1375, 1197, 1537, 1245, 1763, 4301, 897...   \n",
              "...                                                 ...   \n",
              "2894  [519, 317, 317, 317, 375, 317, 317, 432, 317, ...   \n",
              "2895  [30, 30, 30, 30, 30, 42, 206, 183, 206, 159, 3...   \n",
              "2896  [0, 0, 0, 0, 0, 0, 0, 0, 0, 804, 1148, 1217, 1...   \n",
              "2897  [141, 141, 141, 141, 141, 141, 667, 1088, 842,...   \n",
              "2898  [0, 0, 0, 0, 246, 601, 246, 628, 847, 929, 738...   \n",
              "\n",
              "      adjusted_visits_by_day_sum  \n",
              "0                              0  \n",
              "1                              0  \n",
              "2                              0  \n",
              "3                              0  \n",
              "4                              0  \n",
              "...                          ...  \n",
              "2894                           0  \n",
              "2895                           0  \n",
              "2896                           0  \n",
              "2897                           0  \n",
              "2898                           0  \n",
              "\n",
              "[2899 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2d960c5-f39f-4b82-84d4-7d7715c62d37\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PLACEKEY</th>\n",
              "      <th>PARENT_PLACEKEY</th>\n",
              "      <th>LOCATION_NAME</th>\n",
              "      <th>address</th>\n",
              "      <th>place_category</th>\n",
              "      <th>place_subcategory</th>\n",
              "      <th>CATEGORY_TAGS</th>\n",
              "      <th>MEDIAN_DWELL</th>\n",
              "      <th>weighted_median_distance_from_home</th>\n",
              "      <th>num_nearby_stops</th>\n",
              "      <th>nearby_stop_ids</th>\n",
              "      <th>POI_CBG</th>\n",
              "      <th>visitor_counts_cbg_scaled</th>\n",
              "      <th>adjusted_visits_by_day</th>\n",
              "      <th>stops_by_day</th>\n",
              "      <th>stops_by_day_of_week</th>\n",
              "      <th>transit_service_period</th>\n",
              "      <th>stops_by_hour</th>\n",
              "      <th>avg_time_between_stops</th>\n",
              "      <th>stop_frequency</th>\n",
              "      <th>median_headway</th>\n",
              "      <th>upweighting_factor</th>\n",
              "      <th>&lt;5</th>\n",
              "      <th>5-20</th>\n",
              "      <th>21-60</th>\n",
              "      <th>61-240</th>\n",
              "      <th>weighted_avg_dwell_time</th>\n",
              "      <th>&gt;240</th>\n",
              "      <th>adjusted_cbg_visitors</th>\n",
              "      <th>POPULARITY_BY_DAY</th>\n",
              "      <th>POPULARITY_BY_HOUR</th>\n",
              "      <th>adjusted_visits_by_day_sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>224-222@8gk-ttq-sdv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Summit Birmingham</td>\n",
              "      <td>214 Summit Blvd, Vestavia, AL 35243.0, US</td>\n",
              "      <td>Discretionary Retail</td>\n",
              "      <td>Mall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>56.0</td>\n",
              "      <td>9046.647083</td>\n",
              "      <td>2.0</td>\n",
              "      <td>['2899', '2900']</td>\n",
              "      <td>10730128032</td>\n",
              "      <td>752520.499386</td>\n",
              "      <td>[52059, 48388, 27174, 40331, 40104, 39828, 276...</td>\n",
              "      <td>[58.0, 30.0, 0.0, 58.0, 58.0, 58.0, 58.0, 58.0...</td>\n",
              "      <td>{'friday': 290.0, 'saturday': 150.0, 'monday':...</td>\n",
              "      <td>{'friday': ['04:36:28', '21:57:00'], 'saturday...</td>\n",
              "      <td>[0, 0, 0, 0, 6, 2, 4, 6, 6, 6, 4, 2, 6, 6, 6, ...</td>\n",
              "      <td>12.099225</td>\n",
              "      <td>50.0</td>\n",
              "      <td>[13.566666666666666, 14.5]</td>\n",
              "      <td>14.172131</td>\n",
              "      <td>21110</td>\n",
              "      <td>10907</td>\n",
              "      <td>18313</td>\n",
              "      <td>25066</td>\n",
              "      <td>85.866526</td>\n",
              "      <td>8328</td>\n",
              "      <td>{10730128032: 20168, 10730027001: 1034, 107301...</td>\n",
              "      <td>{'Monday': 127734, 'Tuesday': 131759, 'Wednesd...</td>\n",
              "      <td>[4847, 2764, 4847, 2140, 3345, 6973, 10573, 31...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>zzw-22m@8gk-twj-q75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Riverchase Galleria</td>\n",
              "      <td>2000 Riverchase Galleria, Hoover, AL, 35244, US</td>\n",
              "      <td>Discretionary Retail</td>\n",
              "      <td>Mall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>61.0</td>\n",
              "      <td>12857.542473</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['2098']</td>\n",
              "      <td>10730144081</td>\n",
              "      <td>533346.909139</td>\n",
              "      <td>[33590, 33757, 29733, 17008, 18693, 20500, 203...</td>\n",
              "      <td>[14.0, 10.0, 0.0, 14.0, 14.0, 14.0, 14.0, 14.0...</td>\n",
              "      <td>{'friday': 70.0, 'saturday': 50.0, 'monday': 5...</td>\n",
              "      <td>{'friday': ['06:48:00', '18:58:00'], 'saturday...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 4, 2, 4, 0, 0, 2, 0, 0, 4, ...</td>\n",
              "      <td>32.565217</td>\n",
              "      <td>300.0</td>\n",
              "      <td>[5.0]</td>\n",
              "      <td>14.618182</td>\n",
              "      <td>20002</td>\n",
              "      <td>4844</td>\n",
              "      <td>9771</td>\n",
              "      <td>15644</td>\n",
              "      <td>81.012422</td>\n",
              "      <td>5566</td>\n",
              "      <td>{10730144081: 17848, 10730143021: 8676, 107301...</td>\n",
              "      <td>{'Monday': 58108, 'Tuesday': 78471, 'Wednesday...</td>\n",
              "      <td>[8450, 5892, 4722, 6169, 4634, 6082, 9926, 122...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>zzy-222@8gk-tpx-gtv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>River Ridge</td>\n",
              "      <td>4606 Highway 280, Birmingham, AL, 35242, US</td>\n",
              "      <td>Discretionary Retail</td>\n",
              "      <td>Mall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24.0</td>\n",
              "      <td>9826.700561</td>\n",
              "      <td>2.0</td>\n",
              "      <td>['2909', '2917']</td>\n",
              "      <td>11170303034</td>\n",
              "      <td>377023.813828</td>\n",
              "      <td>[16601, 19169, 16714, 20347, 11950, 19960, 195...</td>\n",
              "      <td>[29.0, 15.0, 0.0, 29.0, 29.0, 29.0, 29.0, 29.0...</td>\n",
              "      <td>{'friday': 145.0, 'saturday': 75.0, 'monday': ...</td>\n",
              "      <td>{'friday': ['04:31:35', '21:42:19'], 'saturday...</td>\n",
              "      <td>[0, 0, 0, 0, 2, 2, 3, 2, 2, 3, 2, 4, 2, 2, 3, ...</td>\n",
              "      <td>23.970543</td>\n",
              "      <td>1578.0</td>\n",
              "      <td>[59.55833333333333, 54.35]</td>\n",
              "      <td>23.153846</td>\n",
              "      <td>15637</td>\n",
              "      <td>8890</td>\n",
              "      <td>8252</td>\n",
              "      <td>5268</td>\n",
              "      <td>50.376019</td>\n",
              "      <td>2572</td>\n",
              "      <td>{11170303034: 14520, 11170303441: 8240, 107301...</td>\n",
              "      <td>{'Monday': 104563, 'Tuesday': 122994, 'Wednesd...</td>\n",
              "      <td>[7271, 3682, 3497, 2779, 3867, 3335, 13129, 33...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>225-222@8gk-tv9-cnq</td>\n",
              "      <td>NaN</td>\n",
              "      <td>University Of Alabama At Birmingham</td>\n",
              "      <td>1720 University Blvd, Birmingham, AL 35294</td>\n",
              "      <td>College</td>\n",
              "      <td>University</td>\n",
              "      <td>University</td>\n",
              "      <td>141.0</td>\n",
              "      <td>7823.942284</td>\n",
              "      <td>3.0</td>\n",
              "      <td>['1479', '1480', '1541']</td>\n",
              "      <td>10730045001</td>\n",
              "      <td>319398.478932</td>\n",
              "      <td>[29368, 27407, 25824, 27252, 27028, 26736, 263...</td>\n",
              "      <td>[52.0, 33.0, 0.0, 52.0, 52.0, 52.0, 52.0, 52.0...</td>\n",
              "      <td>{'friday': 260.0, 'saturday': 165.0, 'monday':...</td>\n",
              "      <td>{'friday': ['05:14:27', '22:05:17'], 'saturday...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 2, 3, 6, 4, 6, 6, 5, 6, 6, 6, ...</td>\n",
              "      <td>12.033730</td>\n",
              "      <td>480.5</td>\n",
              "      <td>[38.15, 38.43333333333333, 33.858333333333334]</td>\n",
              "      <td>4.711191</td>\n",
              "      <td>22749</td>\n",
              "      <td>2255</td>\n",
              "      <td>2153</td>\n",
              "      <td>7789</td>\n",
              "      <td>114.652473</td>\n",
              "      <td>14384</td>\n",
              "      <td>{10730045001: 7382, 10730049022: 7772, 1073014...</td>\n",
              "      <td>{'Monday': 30411, 'Tuesday': 29747, 'Wednesday...</td>\n",
              "      <td>[11972, 5343, 7458, 6869, 7015, 8245, 18619, 1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>zzy-222@8gk-twj-kmk</td>\n",
              "      <td>zzy-223@8gk-twj-kmk</td>\n",
              "      <td>Riverchase Promenade</td>\n",
              "      <td>1705 Montgomery Hwy Apt 1735, Hoover, AL, 3524...</td>\n",
              "      <td>Discretionary Retail</td>\n",
              "      <td>Shopping Center</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.0</td>\n",
              "      <td>11646.996678</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['2099']</td>\n",
              "      <td>10730129122</td>\n",
              "      <td>205399.851134</td>\n",
              "      <td>[9301, 8357, 8190, 8175, 8022, 8951, 8418, 110...</td>\n",
              "      <td>[7.0, 5.0, 0.0, 7.0, 7.0, 7.0, 7.0, 7.0, 5.0, ...</td>\n",
              "      <td>{'friday': 35.0, 'saturday': 25.0, 'monday': 2...</td>\n",
              "      <td>{'friday': ['06:55:55', '19:00:42'], 'saturday...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 1, 0, 0, 2, ...</td>\n",
              "      <td>67.839394</td>\n",
              "      <td>2626.0</td>\n",
              "      <td>[43.766666666666666]</td>\n",
              "      <td>16.168675</td>\n",
              "      <td>10014</td>\n",
              "      <td>3500</td>\n",
              "      <td>3597</td>\n",
              "      <td>1937</td>\n",
              "      <td>42.147874</td>\n",
              "      <td>1155</td>\n",
              "      <td>{10730143021: 3794, 10730129122: 3622, 1073014...</td>\n",
              "      <td>{'Monday': 29702, 'Tuesday': 39129, 'Wednesday...</td>\n",
              "      <td>[1423, 1375, 1197, 1537, 1245, 1763, 4301, 897...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2894</th>\n",
              "      <td>223-222@8gk-tsw-tvz</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Church At Southside</td>\n",
              "      <td>500 20th Ave S, Birmingham, AL, 35205, US</td>\n",
              "      <td>Religious Organizations</td>\n",
              "      <td>Religious Organization</td>\n",
              "      <td>Churches,Hindu Temple,Mosque,Sikh Temple,Synag...</td>\n",
              "      <td>27.0</td>\n",
              "      <td>488.611927</td>\n",
              "      <td>4.0</td>\n",
              "      <td>['1492', '1493', '1528', '1529']</td>\n",
              "      <td>10730050002</td>\n",
              "      <td>405.888953</td>\n",
              "      <td>[54, 54, 54, 81, 81, 81, 81, 81, 81, 81, 81, 8...</td>\n",
              "      <td>[68.0, 44.0, 0.0, 68.0, 68.0, 68.0, 68.0, 68.0...</td>\n",
              "      <td>{'friday': 340.0, 'saturday': 220.0, 'monday':...</td>\n",
              "      <td>{'friday': ['05:28:14', '22:18:58'], 'saturday...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 2, 4, 6, 8, 8, 8, 6, 8, 8, 6, ...</td>\n",
              "      <td>9.105706</td>\n",
              "      <td>44.0</td>\n",
              "      <td>[40.0, 40.0, 34.141666666666666, 34.1083333333...</td>\n",
              "      <td>28.785714</td>\n",
              "      <td>61</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>47.556180</td>\n",
              "      <td>12</td>\n",
              "      <td>{10730050002: 275, 10730050001: 132}</td>\n",
              "      <td>{'Monday': 346, 'Tuesday': 346, 'Wednesday': 2...</td>\n",
              "      <td>[519, 317, 317, 317, 375, 317, 317, 432, 317, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2895</th>\n",
              "      <td>226-222@8gk-tt9-4gk</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Huffstutler Paint &amp; Body</td>\n",
              "      <td>712 Graymont Ave N, Birmingham, AL, 35203, US</td>\n",
              "      <td>Personal Services</td>\n",
              "      <td>Auto Body Shop</td>\n",
              "      <td>Body Shops</td>\n",
              "      <td>153.0</td>\n",
              "      <td>19325.559535</td>\n",
              "      <td>10.0</td>\n",
              "      <td>['1134', '1135', '1276', '1277', '1363', '1364...</td>\n",
              "      <td>10730029003</td>\n",
              "      <td>124.493982</td>\n",
              "      <td>[27, 36, 27, 44, 44, 27, 44, 44, 0, 27, 44, 44...</td>\n",
              "      <td>[266.0, 209.0, 0.0, 266.0, 266.0, 266.0, 266.0...</td>\n",
              "      <td>{'friday': 1330.0, 'saturday': 1045.0, 'monday...</td>\n",
              "      <td>{'friday': ['04:56:52', '22:06:13'], 'saturday...</td>\n",
              "      <td>[0, 0, 0, 0, 2, 12, 21, 27, 30, 41, 33, 29, 38...</td>\n",
              "      <td>2.277323</td>\n",
              "      <td>41.5</td>\n",
              "      <td>[10.366666666666667, 10.416666666666666, 19.5,...</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>28</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>138.650943</td>\n",
              "      <td>38</td>\n",
              "      <td>{10730111113: 24, 10730027001: 4, 10730037003:...</td>\n",
              "      <td>{'Monday': 100, 'Tuesday': 112, 'Wednesday': 1...</td>\n",
              "      <td>[30, 30, 30, 30, 30, 42, 206, 183, 206, 159, 3...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2896</th>\n",
              "      <td>226-223@8gk-tv8-mp9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Offices of Real Estate Agents and Brokers - 29...</td>\n",
              "      <td>2911 Crescent Ave, Birmingham, AL 35209</td>\n",
              "      <td>Financial, Legal, Real Estate and Insurance Se...</td>\n",
              "      <td>Real Estate Agents</td>\n",
              "      <td>NaN</td>\n",
              "      <td>197.0</td>\n",
              "      <td>47090.303353</td>\n",
              "      <td>8.0</td>\n",
              "      <td>['2251', '2435', '2436', '2437', '2438', '2446...</td>\n",
              "      <td>10730107022</td>\n",
              "      <td>125.760000</td>\n",
              "      <td>[31, 52, 42, 52, 21, 21, 21, 52, 0, 52, 52, 21...</td>\n",
              "      <td>[355.0, 219.0, 0.0, 355.0, 355.0, 355.0, 355.0...</td>\n",
              "      <td>{'friday': 1775.0, 'saturday': 1095.0, 'monday...</td>\n",
              "      <td>{'friday': ['06:18:21', '21:09:53'], 'saturday...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 14, 21, 39, 25, 45, 36, 40,...</td>\n",
              "      <td>1.858732</td>\n",
              "      <td>36.0</td>\n",
              "      <td>[10.2, 10.216666666666667, 10.133333333333333,...</td>\n",
              "      <td>22.955556</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>42</td>\n",
              "      <td>153.133333</td>\n",
              "      <td>24</td>\n",
              "      <td>{11210113001: 126}</td>\n",
              "      <td>{'Monday': 414, 'Tuesday': 253, 'Wednesday': 2...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 804, 1148, 1217, 1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2897</th>\n",
              "      <td>227-223@8gm-9n5-6c5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LaCole's &amp; Ann's Florist</td>\n",
              "      <td>1604 4th Ave N, Bessemer, AL 35020</td>\n",
              "      <td>Personal Services</td>\n",
              "      <td>Florists</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79.0</td>\n",
              "      <td>6660.742492</td>\n",
              "      <td>13.0</td>\n",
              "      <td>['1060', '1061', '1087', '1088', '1089', '1090...</td>\n",
              "      <td>10730102002</td>\n",
              "      <td>182.390476</td>\n",
              "      <td>[33, 33, 33, 33, 33, 50, 33, 33, 33, 50, 33, 3...</td>\n",
              "      <td>[306.0, 247.0, 0.0, 306.0, 306.0, 306.0, 306.0...</td>\n",
              "      <td>{'friday': 1530.0, 'saturday': 1235.0, 'monday...</td>\n",
              "      <td>{'friday': ['04:17:00', '22:28:00'], 'saturday...</td>\n",
              "      <td>[0, 0, 0, 0, 7, 20, 34, 28, 29, 42, 37, 34, 26...</td>\n",
              "      <td>2.217480</td>\n",
              "      <td>41.0</td>\n",
              "      <td>[11.0, 11.0, 13.2, 13.15, 30.0, 30.0, 38.0, 38...</td>\n",
              "      <td>35.078947</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>136.032468</td>\n",
              "      <td>24</td>\n",
              "      <td>{10730100012: 183}</td>\n",
              "      <td>{'Monday': 351, 'Tuesday': 351, 'Wednesday': 3...</td>\n",
              "      <td>[141, 141, 141, 141, 141, 141, 667, 1088, 842,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2898</th>\n",
              "      <td>zzw-225@8gm-977-rhq</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Inland Seafood Birmingham</td>\n",
              "      <td>2700 Avenue D, Birmingham, AL, 35218, US</td>\n",
              "      <td>Retail for Basic Necessities</td>\n",
              "      <td>Fresh Food Market</td>\n",
              "      <td>Gourmet,Seafood</td>\n",
              "      <td>302.0</td>\n",
              "      <td>6356.216984</td>\n",
              "      <td>7.0</td>\n",
              "      <td>['1211', '1212', '1213', '1214', '1215', '1245...</td>\n",
              "      <td>10730034003</td>\n",
              "      <td>182.332067</td>\n",
              "      <td>[101, 101, 0, 81, 101, 81, 41, 101, 101, 0, 81...</td>\n",
              "      <td>[140.0, 70.0, 0.0, 140.0, 140.0, 140.0, 140.0,...</td>\n",
              "      <td>{'friday': 700.0, 'saturday': 350.0, 'monday':...</td>\n",
              "      <td>{'friday': ['05:31:14', '20:07:58'], 'saturday...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 7, 7, 19, 14, 14, 14, 16, 14, ...</td>\n",
              "      <td>4.194896</td>\n",
              "      <td>36.0</td>\n",
              "      <td>[33.81666666666667, 33.61666666666667, 33.5, 3...</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>27</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>161.500000</td>\n",
              "      <td>47</td>\n",
              "      <td>{10730052001: 133, 10730118043: 50}</td>\n",
              "      <td>{'Monday': 410, 'Tuesday': 437, 'Wednesday': 3...</td>\n",
              "      <td>[0, 0, 0, 0, 246, 601, 246, 628, 847, 929, 738...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2899 rows × 32 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2d960c5-f39f-4b82-84d4-7d7715c62d37')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2d960c5-f39f-4b82-84d4-7d7715c62d37 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2d960c5-f39f-4b82-84d4-7d7715c62d37');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e3389cc6-3f20-433e-b7c2-6b53d2a2cadf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3389cc6-3f20-433e-b7c2-6b53d2a2cadf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e3389cc6-3f20-433e-b7c2-6b53d2a2cadf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c58add84-0a87-42dc-9080-3861172dd61e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('stops_mp')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c58add84-0a87-42dc-9080-3861172dd61e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('stops_mp');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stops_mp"
            }
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hZP7C-cqzagv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}